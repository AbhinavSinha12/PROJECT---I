import sqlite3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import scale

from customplot import *
In [ ]:
# Create your connection.
cnx = sqlite3.connect('soccer_database.sqlite')
df = pd.read_sql_query("SELECT * FROM Player_Attributes", cnx)
In [ ]:
df.columns
In [ ]:
df.describe().transpose()
Data Cleaning: Handling Missing Data
In [ ]:
#is any row NULL ?
df.isnull().any().any(), df.shape
Now letâ€™s try to find how many data points in each column are null.
In [ ]:
df.isnull().sum(axis=0)
Fixing Null Values by Deleting Them
In [ ]:
# Fix it

# Take initial # of rows
rows = df.shape[0]

# Drop the NULL rows
df = df.dropna()
Now if we check the null values and number of rows, we will see that there are no null values and number of rows decreased accordingly.
In [ ]:
#Check if all NULLS are gone ?
print(rows)
df.isnull().any().any(), df.shape
In [ ]:
#How many rows with NULL values?

rows - df.shape[0]
In [ ]:
#Shuffle the rows of df so we get a distributed sample when we display top few rows

df = df.reindex(np.random.permutation(df.index))
In [ ]:
df.head(5)
In [ ]:
df[:10][['penalties', 'overall_rating']]
In [ ]:
df['overall_rating'].corr(df['penalties'])
In [ ]:
potentialFeatures = ['acceleration', 'curve', 'free_kick_accuracy', 'ball_control', 'shot_power', 'stamina']
In [ ]:
# check how the features are correlated with the overall ratings

for f in potentialFeatures:
    related = df['overall_rating'].corr(df[f])
    print("%s: %f" % (f,related))
Data Visualization:
In [ ]:
cols = ['potential',  'crossing', 'finishing', 'heading_accuracy',
       'short_passing', 'volleys', 'dribbling', 'curve', 'free_kick_accuracy',
       'long_passing', 'ball_control', 'acceleration', 'sprint_speed',
       'agility', 'reactions', 'balance', 'shot_power', 'jumping', 'stamina',
       'strength', 'long_shots', 'aggression', 'interceptions', 'positioning',
       'vision', 'penalties', 'marking', 'standing_tackle', 'sliding_tackle',
       'gk_diving', 'gk_handling', 'gk_kicking', 'gk_positioning',
       'gk_reflexes']
In [ ]:
# create a list containing Pearson's correlation between 'overall_rating' with each column in cols
correlations = [ df['overall_rating'].corr(df[f]) for f in cols ]
len(cols), len(correlations)
In [ ]:
# create a function for plotting a dataframe with string columns and numeric values

def plot_dataframe(df, y_label):  
    color='coral'
    fig = plt.gcf()
    fig.set_size_inches(20, 12)
    plt.ylabel(y_label)

    ax = df2.correlation.plot(linewidth=3.3, color=color)
    ax.set_xticks(df2.index)
    ax.set_xticklabels(df2.attributes, rotation=75); #Notice the ; (remove it and see what happens !)
    plt.show()
In [ ]:
# create a dataframe using cols and correlations

df2 = pd.DataFrame({'attributes': cols, 'correlation': correlations}) 
In [ ]:
# let's plot above dataframe using the function we created
    
plot_dataframe(df2, 'Player\'s Overall Rating')
Analysis of Findings
In [ ]:
# Define the features you want to use for grouping players

select5features = ['gk_kicking', 'potential', 'marking', 'interceptions', 'standing_tackle']
select5features
In [ ]:
# Generate a new dataframe by selecting the features you just defined

df_select = df[select5features].copy(deep=True)
df_select.head()
Perform KMeans Clustering
In [ ]:
# Perform scaling on the dataframe containing the features

data = scale(df_select)

# Define number of clusters
noOfClusters = 4

# Train a model
model = KMeans(init='k-means++', n_clusters=noOfClusters, n_init=20).fit(data)
print(90*'_')
print("\nCount of players in each cluster")
print(90*'_')

pd.value_counts(model.labels_, sort=False)
In [ ]:
# Create a composite dataframe for plotting
# ... Use custom function declared in customplot.py (which we imported at the beginning of this notebook)

P = pd_centers(featuresUsed=select5features, centers=model.cluster_centers_)
P
In [ ]:
# For plotting the graph inside the notebook itself, we use the following command

%matplotlib inline
parallel_plot(P)
